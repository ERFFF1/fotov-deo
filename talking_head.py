#!/usr/bin/env python3
"""
Geli≈ümi≈ü Konu≈üan Kafa (Talking Head) Sistemi
Wav2Lip ve SadTalker entegrasyonu ile fotoƒüraflarƒ± konu≈üturur
"""

import cv2
import numpy as np
import sys
import os
import subprocess
from pathlib import Path
import argparse
import json
from datetime import datetime
from typing import Optional, Tuple, List, Dict
import tempfile
import shutil
import requests
from tqdm import tqdm

class TalkingHeadGenerator:
    def __init__(self, method='wav2lip'):
        """
        Konu≈üan kafa √ºretici ba≈ülatƒ±cƒ±
        
        Args:
            method (str): 'wav2lip', 'sadtalker' se√ßenekleri
        """
        self.method = method
        self.setup_generator()
        
    def setup_generator(self):
        """Se√ßilen y√∂nteme g√∂re √ºretici sistemini kur"""
        if self.method == 'wav2lip':
            self.setup_wav2lip()
        elif self.method == 'sadtalker':
            self.setup_sadtalker()
    
    def setup_wav2lip(self):
        """Wav2Lip sistemini kur"""
        try:
            # Wav2Lip klas√∂r√ºn√º kontrol et
            wav2lip_dir = Path("models/wav2lip")
            if not wav2lip_dir.exists():
                print("üì• Wav2Lip indiriliyor...")
                self.download_wav2lip()
            
            # Model dosyasƒ±nƒ± kontrol et
            model_path = wav2lip_dir / "Wav2Lip.pth"
            if not model_path.exists():
                print("üì• Wav2Lip modeli indiriliyor...")
                self.download_wav2lip_model()
            
            print("‚úÖ Wav2Lip sistemi hazƒ±r")
            
        except Exception as e:
            print(f"‚ùå Wav2Lip kurulum hatasƒ±: {e}")
            print("‚ö†Ô∏è  SadTalker'a ge√ßiliyor...")
            self.method = 'sadtalker'
            self.setup_sadtalker()
    
    def setup_sadtalker(self):
        """SadTalker sistemini kur"""
        try:
            # SadTalker klas√∂r√ºn√º kontrol et
            sadtalker_dir = Path("models/sadtalker")
            if not sadtalker_dir.exists():
                print("üì• SadTalker indiriliyor...")
                self.download_sadtalker()
            
            print("‚úÖ SadTalker sistemi hazƒ±r")
            
        except Exception as e:
            print(f"‚ùå SadTalker kurulum hatasƒ±: {e}")
            print("‚ö†Ô∏è  Basit OpenCV y√∂ntemine ge√ßiliyor...")
            self.method = 'opencv'
    
    def download_wav2lip(self):
        """Wav2Lip repository'sini indir"""
        try:
            wav2lip_dir = Path("models/wav2lip")
            wav2lip_dir.mkdir(parents=True, exist_ok=True)
            
            # Git clone komutu
            cmd = [
                'git', 'clone', 
                'https://github.com/Rudrabha/Wav2Lip.git',
                str(wav2lip_dir)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            print("‚úÖ Wav2Lip indirildi")
            
        except Exception as e:
            print(f"‚ùå Wav2Lip indirme hatasƒ±: {e}")
            raise
    
    def download_wav2lip_model(self):
        """Wav2Lip modelini indir"""
        try:
            model_url = "https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIYOXefzlSSW0WFlFR_6UDg?e=n9ljGW&download=1"
            model_path = Path("models/wav2lip/Wav2Lip.pth")
            
            print("üì• Model indiriliyor (bu i≈ülem biraz zaman alabilir)...")
            
            response = requests.get(model_url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(model_path, 'wb') as f:
                with tqdm(total=total_size, unit='B', unit_scale=True, desc="Model indiriliyor") as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))
            
            print("‚úÖ Wav2Lip modeli indirildi")
            
        except Exception as e:
            print(f"‚ùå Model indirme hatasƒ±: {e}")
            raise
    
    def download_sadtalker(self):
        """SadTalker repository'sini indir"""
        try:
            sadtalker_dir = Path("models/sadtalker")
            sadtalker_dir.mkdir(parents=True, exist_ok=True)
            
            # Git clone komutu
            cmd = [
                'git', 'clone', 
                'https://github.com/Winfredy/SadTalker.git',
                str(sadtalker_dir)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            print("‚úÖ SadTalker indirildi")
            
        except Exception as e:
            print(f"‚ùå SadTalker indirme hatasƒ±: {e}")
            raise
    
    def preprocess_image_for_wav2lip(self, image_path: str, output_path: str) -> bool:
        """Wav2Lip i√ßin g√∂r√ºnt√ºy√º √∂n i≈üle"""
        try:
            # G√∂r√ºnt√ºy√º y√ºkle
            image = cv2.imread(image_path)
            if image is None:
                return False
            
            # Y√ºz tespiti
            face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
            )
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) == 0:
                print("‚ö†Ô∏è  G√∂r√ºnt√ºde y√ºz bulunamadƒ±")
                return False
            
            # En b√ºy√ºk y√ºz√º al
            largest_face = max(faces, key=lambda x: x[2] * x[3])
            x, y, w, h = largest_face
            
            # Y√ºz√º kƒ±rp ve 512x512'e yeniden boyutlandƒ±r
            face_crop = image[y:y+h, x:x+w]
            resized_face = cv2.resize(face_crop, (512, 512))
            
            # Kaydet
            cv2.imwrite(output_path, resized_face)
            return True
            
        except Exception as e:
            print(f"‚ùå G√∂r√ºnt√º √∂n i≈üleme hatasƒ±: {e}")
            return False
    
    def generate_talking_head_wav2lip(self, image_path: str, audio_path: str, output_path: str) -> Dict:
        """Wav2Lip ile konu≈üan kafa √ºret"""
        try:
            wav2lip_dir = Path("models/wav2lip")
            model_path = wav2lip_dir / "Wav2Lip.pth"
            
            if not model_path.exists():
                return {
                    'success': False,
                    'error': 'Wav2Lip modeli bulunamadƒ±',
                    'output_path': None
                }
            
            # Ge√ßici dosyalar
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_image = Path(temp_dir) / "processed_face.jpg"
                
                # G√∂r√ºnt√ºy√º √∂n i≈üle
                if not self.preprocess_image_for_wav2lip(image_path, str(temp_image)):
                    return {
                        'success': False,
                        'error': 'G√∂r√ºnt√º √∂n i≈üleme ba≈üarƒ±sƒ±z',
                        'output_path': None
                    }
                
                # Wav2Lip inference komutu
                cmd = [
                    'python', str(wav2lip_dir / "inference.py"),
                    '--checkpoint_path', str(model_path),
                    '--face', str(temp_image),
                    '--audio', audio_path,
                    '--outfile', output_path
                ]
                
                print(f"üé¨ Wav2Lip ile konu≈üan kafa √ºretiliyor...")
                print(f"   G√∂r√ºnt√º: {image_path}")
                print(f"   Ses: {audio_path}")
                print(f"   √áƒ±ktƒ±: {output_path}")
                
                # Komutu √ßalƒ±≈ütƒ±r
                result = subprocess.run(cmd, capture_output=True, text=True, cwd=wav2lip_dir)
                
                if result.returncode == 0:
                    print("‚úÖ Wav2Lip konu≈üan kafa √ºretimi tamamlandƒ±")
                    
                    return {
                        'success': True,
                        'method': 'wav2lip',
                        'input_image': image_path,
                        'input_audio': audio_path,
                        'output_path': output_path,
                        'timestamp': datetime.now().isoformat()
                    }
                else:
                    return {
                        'success': False,
                        'error': f'Wav2Lip hatasƒ±: {result.stderr}',
                        'output_path': None
                    }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'Wav2Lip √ºretim hatasƒ±: {e}',
                'output_path': None
            }
    
    def generate_talking_head_sadtalker(self, image_path: str, audio_path: str, output_path: str) -> Dict:
        """SadTalker ile konu≈üan kafa √ºret"""
        try:
            sadtalker_dir = Path("models/sadtalker")
            
            if not sadtalker_dir.exists():
                return {
                    'success': False,
                    'error': 'SadTalker bulunamadƒ±',
                    'output_path': None
                }
            
            # SadTalker inference komutu
            cmd = [
                'python', str(sadtalker_dir / "inference.py"),
                '--driven_audio', audio_path,
                '--source_image', image_path,
                '--enhancer', 'gfpgan',
                '--result_dir', str(Path(output_path).parent),
                '--still',  # Sadece kafa hareketi
                '--preprocess', 'full'  # Tam √∂n i≈üleme
            ]
            
            print(f"üé¨ SadTalker ile konu≈üan kafa √ºretiliyor...")
            print(f"   G√∂r√ºnt√º: {image_path}")
            print(f"   Ses: {audio_path}")
            print(f"   √áƒ±ktƒ±: {output_path}")
            
            # Komutu √ßalƒ±≈ütƒ±r
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=sadtalker_dir)
            
            if result.returncode == 0:
                # SadTalker √ßƒ±ktƒ± dosyasƒ±nƒ± bul
                result_dir = Path(output_path).parent
                sadtalker_output = None
                
                for file in result_dir.glob("*.mp4"):
                    if "sadtalker" in file.name.lower():
                        sadtalker_output = file
                        break
                
                if sadtalker_output and sadtalker_output.exists():
                    # √áƒ±ktƒ± dosyasƒ±nƒ± istenen konuma ta≈üƒ±
                    shutil.move(str(sadtalker_output), output_path)
                    
                    print("‚úÖ SadTalker konu≈üan kafa √ºretimi tamamlandƒ±")
                    
                    return {
                        'success': True,
                        'method': 'sadtalker',
                        'input_image': image_path,
                        'input_audio': audio_path,
                        'output_path': output_path,
                        'timestamp': datetime.now().isoformat()
                    }
                else:
                    return {
                        'success': False,
                        'error': 'SadTalker √ßƒ±ktƒ± dosyasƒ± bulunamadƒ±',
                        'output_path': None
                    }
            else:
                return {
                    'success': False,
                    'error': f'SadTalker hatasƒ±: {result.stderr}',
                    'output_path': None
                }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'SadTalker √ºretim hatasƒ±: {e}',
                'output_path': None
            }
    
    def generate_talking_head_opencv(self, image_path: str, audio_path: str, output_path: str) -> Dict:
        """OpenCV ile basit konu≈üan kafa √ºret (demo)"""
        try:
            # G√∂r√ºnt√ºy√º y√ºkle
            image = cv2.imread(image_path)
            if image is None:
                return {
                    'success': False,
                    'error': f'G√∂r√ºnt√º y√ºklenemedi: {image_path}',
                    'output_path': None
                }
            
            # Y√ºz tespiti
            face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
            )
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) == 0:
                return {
                    'success': False,
                    'error': 'G√∂r√ºnt√ºde y√ºz bulunamadƒ±',
                    'output_path': None
                }
            
            # En b√ºy√ºk y√ºz√º al
            largest_face = max(faces, key=lambda x: x[2] * x[3])
            x, y, w, h = largest_face
            
            # Basit animasyon (y√ºz√º hafif√ße hareket ettir)
            frames = []
            fps = 25
            duration = 3  # 3 saniye
            
            for i in range(fps * duration):
                # Y√ºz√º hafif√ße hareket ettir
                offset_x = int(5 * np.sin(2 * np.pi * i / fps))
                offset_y = int(3 * np.cos(2 * np.pi * i / fps))
                
                # Yeni pozisyon
                new_x = max(0, x + offset_x)
                new_y = max(0, y + offset_y)
                new_w = min(image.shape[1] - new_x, w)
                new_h = min(image.shape[0] - new_y, h)
                
                # Frame olu≈ütur
                frame = image.copy()
                
                # Y√ºz b√∂lgesini vurgula
                cv2.rectangle(frame, (new_x, new_y), (new_x + new_w, new_y + new_h), (0, 255, 0), 2)
                
                # "Konu≈üuyor" efekti (basit)
                if i % 10 < 5:  # Yanƒ±p s√∂nen efekt
                    cv2.circle(frame, (new_x + new_w//2, new_y + new_h//2), 5, (0, 0, 255), -1)
                
                frames.append(frame)
            
            # Video olu≈ütur
            height, width, _ = image.shape
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            for frame in frames:
                out.write(frame)
            
            out.release()
            
            print("‚úÖ OpenCV konu≈üan kafa √ºretimi tamamlandƒ± (demo)")
            
            return {
                'success': True,
                'method': 'opencv_demo',
                'input_image': image_path,
                'input_audio': audio_path,
                'output_path': output_path,
                'timestamp': datetime.now().isoformat()
            }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'OpenCV √ºretim hatasƒ±: {e}',
                'output_path': None
            }
    
    def generate_talking_head(self, image_path: str, audio_path: str, output_path: Optional[str] = None) -> Dict:
        """Ana konu≈üan kafa √ºretim fonksiyonu"""
        # Dosya kontrol√º
        if not os.path.exists(image_path):
            return {
                'success': False,
                'error': f'G√∂r√ºnt√º dosyasƒ± bulunamadƒ±: {image_path}',
                'output_path': None
            }
        
        if not os.path.exists(audio_path):
            return {
                'success': False,
                'error': f'Ses dosyasƒ± bulunamadƒ±: {audio_path}',
                'output_path': None
            }
        
        # √áƒ±ktƒ± dosya yolu belirle
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"talking_head_{self.method}_{timestamp}.mp4"
            output_path = f"outputs/talking_heads/{filename}"
        
        # √áƒ±ktƒ± klas√∂r√ºn√º olu≈ütur
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        print(f"üé¨ Konu≈üan kafa √ºretimi ba≈ülƒ±yor...")
        print(f"   Y√∂ntem: {self.method}")
        print(f"   G√∂r√ºnt√º: {image_path}")
        print(f"   Ses: {audio_path}")
        print(f"   √áƒ±ktƒ±: {output_path}")
        
        # Y√∂nteme g√∂re √ºretim yap
        if self.method == 'wav2lip':
            return self.generate_talking_head_wav2lip(image_path, audio_path, output_path)
        elif self.method == 'sadtalker':
            return self.generate_talking_head_sadtalker(image_path, audio_path, output_path)
        elif self.method == 'opencv':
            return self.generate_talking_head_opencv(image_path, audio_path, output_path)
        else:
            return {
                'success': False,
                'error': f'Bilinmeyen y√∂ntem: {self.method}',
                'output_path': None
            }
    
    def batch_generate_talking_heads(self, images_dir: str, audio_path: str, output_dir: str = "outputs/talking_heads_batch") -> Dict:
        """Birden fazla g√∂r√ºnt√º i√ßin toplu konu≈üan kafa √ºretimi"""
        if not os.path.exists(images_dir):
            return {
                'success': False,
                'error': f'G√∂r√ºnt√º klas√∂r√º bulunamadƒ±: {images_dir}',
                'processed_count': 0
            }
        
        if not os.path.exists(audio_path):
            return {
                'success': False,
                'error': f'Ses dosyasƒ± bulunamadƒ±: {audio_path}',
                'processed_count': 0
            }
        
        # Desteklenen dosya formatlarƒ±
        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        
        # G√∂r√ºnt√º dosyalarƒ±nƒ± bul
        image_files = [f for f in Path(images_dir).iterdir() 
                      if f.suffix.lower() in supported_formats]
        
        if not image_files:
            return {
                'success': False,
                'error': f'G√∂r√ºnt√º dosyasƒ± bulunamadƒ±: {images_dir}',
                'processed_count': 0
            }
        
        print(f"üîÑ {len(image_files)} g√∂r√ºnt√º i√ßin toplu konu≈üan kafa √ºretimi...")
        
        # √áƒ±ktƒ± klas√∂r√ºn√º olu≈ütur
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        results = []
        success_count = 0
        
        for i, image_file in enumerate(image_files, 1):
            print(f"   [{i}/{len(image_files)}] {image_file.name}")
            
            # √áƒ±ktƒ± dosya yolu
            output_file = output_path / f"talking_{image_file.stem}.mp4"
            
            # Konu≈üan kafa √ºret
            result = self.generate_talking_head(str(image_file), audio_path, str(output_file))
            results.append(result)
            
            if result['success']:
                success_count += 1
        
        print(f"‚úÖ Toplu konu≈üan kafa √ºretimi tamamlandƒ±: {success_count}/{len(image_files)} ba≈üarƒ±lƒ±")
        
        return {
            'success': True,
            'images_dir': images_dir,
            'audio_path': audio_path,
            'output_dir': output_dir,
            'total_files': len(image_files),
            'processed_count': success_count,
            'results': results,
            'timestamp': datetime.now().isoformat()
        }

def main():
    parser = argparse.ArgumentParser(description='Geli≈ümi≈ü Konu≈üan Kafa √úretim Sistemi')
    parser.add_argument('--image', help='Kaynak g√∂r√ºnt√º dosyasƒ±')
    parser.add_argument('--audio', help='Ses dosyasƒ± (wav/mp3)')
    parser.add_argument('--method', choices=['wav2lip', 'sadtalker', 'opencv'], 
                       default='wav2lip', help='√úretim y√∂ntemi')
    parser.add_argument('--output', help='√áƒ±ktƒ± video yolu')
    parser.add_argument('--batch', action='store_true', 
                       help='Toplu √ºretim (image klas√∂r olmalƒ±)')
    parser.add_argument('--images-dir', help='G√∂r√ºnt√º klas√∂r√º (batch modu i√ßin)')
    
    args = parser.parse_args()
    
    # Konu≈üan kafa √ºretici olu≈ütur
    generator = TalkingHeadGenerator(method=args.method)
    
    if args.batch and args.images_dir and args.audio:
        # Toplu √ºretim
        result = generator.batch_generate_talking_heads(args.images_dir, args.audio, args.output)
        
        if result['success']:
            print(f"\nüìä Toplu √úretim Sonu√ßlarƒ±:")
            print(f"   G√∂r√ºnt√º klas√∂r√º: {result['images_dir']}")
            print(f"   Ses dosyasƒ±: {result['audio_path']}")
            print(f"   Toplam dosya: {result['total_files']}")
            print(f"   ƒ∞≈ülenen: {result['processed_count']}")
            print(f"   √áƒ±ktƒ± klas√∂r√º: {result['output_dir']}")
        else:
            print(f"‚ùå Hata: {result['error']}")
    
    elif args.image and args.audio:
        # Tek dosya √ºretim
        result = generator.generate_talking_head(args.image, args.audio, args.output)
        
        if result['success']:
            print(f"\nüìä Konu≈üan Kafa √úretim Sonu√ßlarƒ±:")
            print(f"   Y√∂ntem: {result['method']}")
            print(f"   G√∂r√ºnt√º: {result['input_image']}")
            print(f"   Ses: {result['input_audio']}")
            print(f"   √áƒ±ktƒ±: {result['output_path']}")
        else:
            print(f"‚ùå Hata: {result['error']}")
    
    else:
        print("‚ùå L√ºtfen gerekli parametreleri belirtin. --help ile yardƒ±m alƒ±n.")
        print("\n√ñrnek kullanƒ±mlar:")
        print("  python talking_head.py --image face.jpg --audio voice.wav")
        print("  python talking_head.py --images-dir photos/ --audio voice.wav --batch")
        print("  python talking_head.py --image face.jpg --audio voice.wav --method sadtalker")

if __name__ == "__main__":
    main()
