#!/usr/bin/env python3
"""
GeliÅŸmiÅŸ KonuÅŸan Kafa (Talking Head) Sistemi
Wav2Lip ve SadTalker entegrasyonu ile fotoÄŸraflarÄ± konuÅŸturur
"""

import cv2
import numpy as np
import sys
import os
import subprocess
from pathlib import Path
import argparse
import json
from datetime import datetime
from typing import Optional, Tuple, List, Dict
import tempfile
import shutil
import requests
from tqdm import tqdm

class TalkingHeadGenerator:
    def __init__(self, method='wav2lip'):
        """
        KonuÅŸan kafa Ã¼retici baÅŸlatÄ±cÄ±
        
        Args:
            method (str): 'wav2lip', 'sadtalker' seÃ§enekleri
        """
        self.method = method
        self.setup_generator()
        
    def setup_generator(self):
        """SeÃ§ilen yÃ¶nteme gÃ¶re Ã¼retici sistemini kur"""
        if self.method == 'wav2lip':
            self.setup_wav2lip()
        elif self.method == 'sadtalker':
            self.setup_sadtalker()
    
    def setup_wav2lip(self):
        """Wav2Lip sistemini kur"""
        try:
            # Wav2Lip klasÃ¶rÃ¼nÃ¼ kontrol et
            wav2lip_dir = Path("models/wav2lip")
            if not wav2lip_dir.exists():
                print("ğŸ“¥ Wav2Lip indiriliyor...")
                self.download_wav2lip()
            
            # Model dosyasÄ±nÄ± kontrol et
            model_path = wav2lip_dir / "Wav2Lip.pth"
            if not model_path.exists():
                print("ğŸ“¥ Wav2Lip modeli indiriliyor...")
                self.download_wav2lip_model()
            
            print("âœ… Wav2Lip sistemi hazÄ±r")
            
        except Exception as e:
            print(f"âŒ Wav2Lip kurulum hatasÄ±: {e}")
            print("âš ï¸  SadTalker'a geÃ§iliyor...")
            self.method = 'sadtalker'
            self.setup_sadtalker()
    
    def setup_sadtalker(self):
        """SadTalker sistemini kur"""
        try:
            # SadTalker klasÃ¶rÃ¼nÃ¼ kontrol et
            sadtalker_dir = Path("models/sadtalker")
            if not sadtalker_dir.exists():
                print("ğŸ“¥ SadTalker indiriliyor...")
                self.download_sadtalker()
            
            print("âœ… SadTalker sistemi hazÄ±r")
            
        except Exception as e:
            print(f"âŒ SadTalker kurulum hatasÄ±: {e}")
            print("âš ï¸  Basit OpenCV yÃ¶ntemine geÃ§iliyor...")
            self.method = 'opencv'
    
    def download_wav2lip(self):
        """Wav2Lip repository'sini indir"""
        try:
            wav2lip_dir = Path("models/wav2lip")
            wav2lip_dir.mkdir(parents=True, exist_ok=True)
            
            # Git clone komutu
            cmd = [
                'git', 'clone', 
                'https://github.com/Rudrabha/Wav2Lip.git',
                str(wav2lip_dir)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            print("âœ… Wav2Lip indirildi")
            
        except Exception as e:
            print(f"âŒ Wav2Lip indirme hatasÄ±: {e}")
            raise
    
    def download_wav2lip_model(self):
        """Wav2Lip modelini indir"""
        try:
            model_url = "https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIYOXefzlSSW0WFlFR_6UDg?e=n9ljGW&download=1"
            model_path = Path("models/wav2lip/Wav2Lip.pth")
            
            print("ğŸ“¥ Model indiriliyor (bu iÅŸlem biraz zaman alabilir)...")
            
            response = requests.get(model_url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(model_path, 'wb') as f:
                with tqdm(total=total_size, unit='B', unit_scale=True, desc="Model indiriliyor") as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))
            
            print("âœ… Wav2Lip modeli indirildi")
            
        except Exception as e:
            print(f"âŒ Model indirme hatasÄ±: {e}")
            raise
    
    def download_sadtalker(self):
        """SadTalker repository'sini indir"""
        try:
            sadtalker_dir = Path("models/sadtalker")
            sadtalker_dir.mkdir(parents=True, exist_ok=True)
            
            # Git clone komutu
            cmd = [
                'git', 'clone', 
                'https://github.com/Winfredy/SadTalker.git',
                str(sadtalker_dir)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            print("âœ… SadTalker indirildi")
            
        except Exception as e:
            print(f"âŒ SadTalker indirme hatasÄ±: {e}")
            raise
    
    def preprocess_image_for_wav2lip(self, image_path: str, output_path: str) -> bool:
        """Wav2Lip iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ Ã¶n iÅŸle"""
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
            image = cv2.imread(image_path)
            if image is None:
                return False
            
            # YÃ¼z tespiti
            face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
            )
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) == 0:
                print("âš ï¸  GÃ¶rÃ¼ntÃ¼de yÃ¼z bulunamadÄ±")
                return False
            
            # En bÃ¼yÃ¼k yÃ¼zÃ¼ al
            largest_face = max(faces, key=lambda x: x[2] * x[3])
            x, y, w, h = largest_face
            
            # YÃ¼zÃ¼ kÄ±rp ve 512x512'e yeniden boyutlandÄ±r
            face_crop = image[y:y+h, x:x+w]
            resized_face = cv2.resize(face_crop, (512, 512))
            
            # Kaydet
            cv2.imwrite(output_path, resized_face)
            return True
            
        except Exception as e:
            print(f"âŒ GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme hatasÄ±: {e}")
            return False
    
    def generate_talking_head_wav2lip(self, image_path: str, audio_path: str, output_path: str) -> Dict:
        """Wav2Lip ile konuÅŸan kafa Ã¼ret"""
        try:
            wav2lip_dir = Path("models/wav2lip")
            model_path = wav2lip_dir / "Wav2Lip.pth"
            
            if not model_path.exists():
                return {
                    'success': False,
                    'error': 'Wav2Lip modeli bulunamadÄ±',
                    'output_path': None
                }
            
            # GeÃ§ici dosyalar
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_image = Path(temp_dir) / "processed_face.jpg"
                
                # GÃ¶rÃ¼ntÃ¼yÃ¼ Ã¶n iÅŸle
                if not self.preprocess_image_for_wav2lip(image_path, str(temp_image)):
                    return {
                        'success': False,
                        'error': 'GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme baÅŸarÄ±sÄ±z',
                        'output_path': None
                    }
                
                # Wav2Lip inference komutu
                cmd = [
                    'python', str(wav2lip_dir / "inference.py"),
                    '--checkpoint_path', str(model_path),
                    '--face', str(temp_image),
                    '--audio', audio_path,
                    '--outfile', output_path
                ]
                
                print(f"ğŸ¬ Wav2Lip ile konuÅŸan kafa Ã¼retiliyor...")
                print(f"   GÃ¶rÃ¼ntÃ¼: {image_path}")
                print(f"   Ses: {audio_path}")
                print(f"   Ã‡Ä±ktÄ±: {output_path}")
                
                # Komutu Ã§alÄ±ÅŸtÄ±r
                result = subprocess.run(cmd, capture_output=True, text=True, cwd=wav2lip_dir)
                
                if result.returncode == 0:
                    print("âœ… Wav2Lip konuÅŸan kafa Ã¼retimi tamamlandÄ±")
                    
                    return {
                        'success': True,
                        'method': 'wav2lip',
                        'input_image': image_path,
                        'input_audio': audio_path,
                        'output_path': output_path,
                        'timestamp': datetime.now().isoformat()
                    }
                else:
                    return {
                        'success': False,
                        'error': f'Wav2Lip hatasÄ±: {result.stderr}',
                        'output_path': None
                    }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'Wav2Lip Ã¼retim hatasÄ±: {e}',
                'output_path': None
            }
    
    def generate_talking_head_sadtalker(self, image_path: str, audio_path: str, output_path: str) -> Dict:
        """SadTalker ile konuÅŸan kafa Ã¼ret"""
        try:
            sadtalker_dir = Path("models/sadtalker")
            
            if not sadtalker_dir.exists():
                return {
                    'success': False,
                    'error': 'SadTalker bulunamadÄ±',
                    'output_path': None
                }
            
            # SadTalker inference komutu
            cmd = [
                'python', str(sadtalker_dir / "inference.py"),
                '--driven_audio', audio_path,
                '--source_image', image_path,
                '--enhancer', 'gfpgan',
                '--result_dir', str(Path(output_path).parent),
                '--still',  # Sadece kafa hareketi
                '--preprocess', 'full'  # Tam Ã¶n iÅŸleme
            ]
            
            print(f"ğŸ¬ SadTalker ile konuÅŸan kafa Ã¼retiliyor...")
            print(f"   GÃ¶rÃ¼ntÃ¼: {image_path}")
            print(f"   Ses: {audio_path}")
            print(f"   Ã‡Ä±ktÄ±: {output_path}")
            
            # Komutu Ã§alÄ±ÅŸtÄ±r
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=sadtalker_dir)
            
            if result.returncode == 0:
                # SadTalker Ã§Ä±ktÄ± dosyasÄ±nÄ± bul
                result_dir = Path(output_path).parent
                sadtalker_output = None
                
                for file in result_dir.glob("*.mp4"):
                    if "sadtalker" in file.name.lower():
                        sadtalker_output = file
                        break
                
                if sadtalker_output and sadtalker_output.exists():
                    # Ã‡Ä±ktÄ± dosyasÄ±nÄ± istenen konuma taÅŸÄ±
                    shutil.move(str(sadtalker_output), output_path)
                    
                    print("âœ… SadTalker konuÅŸan kafa Ã¼retimi tamamlandÄ±")
                    
                    return {
                        'success': True,
                        'method': 'sadtalker',
                        'input_image': image_path,
                        'input_audio': audio_path,
                        'output_path': output_path,
                        'timestamp': datetime.now().isoformat()
                    }
                else:
                    return {
                        'success': False,
                        'error': 'SadTalker Ã§Ä±ktÄ± dosyasÄ± bulunamadÄ±',
                        'output_path': None
                    }
            else:
                return {
                    'success': False,
                    'error': f'SadTalker hatasÄ±: {result.stderr}',
                    'output_path': None
                }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'SadTalker Ã¼retim hatasÄ±: {e}',
                'output_path': None
            }
    
    def generate_talking_head_opencv(self, image_path: str, audio_path: str, output_path: str) -> Dict:
        """OpenCV ile basit konuÅŸan kafa Ã¼ret (demo)"""
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
            image = cv2.imread(image_path)
            if image is None:
                return {
                    'success': False,
                    'error': f'GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi: {image_path}',
                    'output_path': None
                }
            
            # YÃ¼z tespiti
            face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
            )
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) == 0:
                return {
                    'success': False,
                    'error': 'GÃ¶rÃ¼ntÃ¼de yÃ¼z bulunamadÄ±',
                    'output_path': None
                }
            
            # En bÃ¼yÃ¼k yÃ¼zÃ¼ al
            largest_face = max(faces, key=lambda x: x[2] * x[3])
            x, y, w, h = largest_face
            
            # Basit animasyon (yÃ¼zÃ¼ hafifÃ§e hareket ettir)
            frames = []
            fps = 25
            duration = 3  # 3 saniye
            
            for i in range(fps * duration):
                # YÃ¼zÃ¼ hafifÃ§e hareket ettir
                offset_x = int(5 * np.sin(2 * np.pi * i / fps))
                offset_y = int(3 * np.cos(2 * np.pi * i / fps))
                
                # Yeni pozisyon
                new_x = max(0, x + offset_x)
                new_y = max(0, y + offset_y)
                new_w = min(image.shape[1] - new_x, w)
                new_h = min(image.shape[0] - new_y, h)
                
                # Frame oluÅŸtur
                frame = image.copy()
                
                # YÃ¼z bÃ¶lgesini vurgula
                cv2.rectangle(frame, (new_x, new_y), (new_x + new_w, new_y + new_h), (0, 255, 0), 2)
                
                # "KonuÅŸuyor" efekti (basit)
                if i % 10 < 5:  # YanÄ±p sÃ¶nen efekt
                    cv2.circle(frame, (new_x + new_w//2, new_y + new_h//2), 5, (0, 0, 255), -1)
                
                frames.append(frame)
            
            # Video oluÅŸtur
            height, width, _ = image.shape
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            for frame in frames:
                out.write(frame)
            
            out.release()
            
            print("âœ… OpenCV konuÅŸan kafa Ã¼retimi tamamlandÄ± (demo)")
            
            return {
                'success': True,
                'method': 'opencv_demo',
                'input_image': image_path,
                'input_audio': audio_path,
                'output_path': output_path,
                'timestamp': datetime.now().isoformat()
            }
        
        except Exception as e:
            return {
                'success': False,
                'error': f'OpenCV Ã¼retim hatasÄ±: {e}',
                'output_path': None
            }
    
    def generate_talking_head(self, image_path: str, audio_path: str, output_path: Optional[str] = None) -> Dict:
        """Ana konuÅŸan kafa Ã¼retim fonksiyonu"""
        # Dosya kontrolÃ¼
        if not os.path.exists(image_path):
            return {
                'success': False,
                'error': f'GÃ¶rÃ¼ntÃ¼ dosyasÄ± bulunamadÄ±: {image_path}',
                'output_path': None
            }
        
        if not os.path.exists(audio_path):
            return {
                'success': False,
                'error': f'Ses dosyasÄ± bulunamadÄ±: {audio_path}',
                'output_path': None
            }
        
        # Ã‡Ä±ktÄ± dosya yolu belirle
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"talking_head_{self.method}_{timestamp}.mp4"
            output_path = f"outputs/talking_heads/{filename}"
        
        # Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ¬ KonuÅŸan kafa Ã¼retimi baÅŸlÄ±yor...")
        print(f"   YÃ¶ntem: {self.method}")
        print(f"   GÃ¶rÃ¼ntÃ¼: {image_path}")
        print(f"   Ses: {audio_path}")
        print(f"   Ã‡Ä±ktÄ±: {output_path}")
        
        # YÃ¶nteme gÃ¶re Ã¼retim yap
        if self.method == 'wav2lip':
            return self.generate_talking_head_wav2lip(image_path, audio_path, output_path)
        elif self.method == 'sadtalker':
            return self.generate_talking_head_sadtalker(image_path, audio_path, output_path)
        elif self.method == 'opencv':
            return self.generate_talking_head_opencv(image_path, audio_path, output_path)
        else:
            return {
                'success': False,
                'error': f'Bilinmeyen yÃ¶ntem: {self.method}',
                'output_path': None
            }
    
    def batch_generate_talking_heads(self, images_dir: str, audio_path: str, output_dir: str = "outputs/talking_heads_batch") -> Dict:
        """Birden fazla gÃ¶rÃ¼ntÃ¼ iÃ§in toplu konuÅŸan kafa Ã¼retimi"""
        if not os.path.exists(images_dir):
            return {
                'success': False,
                'error': f'GÃ¶rÃ¼ntÃ¼ klasÃ¶rÃ¼ bulunamadÄ±: {images_dir}',
                'processed_count': 0
            }
        
        if not os.path.exists(audio_path):
            return {
                'success': False,
                'error': f'Ses dosyasÄ± bulunamadÄ±: {audio_path}',
                'processed_count': 0
            }
        
        # Desteklenen dosya formatlarÄ±
        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        
        # GÃ¶rÃ¼ntÃ¼ dosyalarÄ±nÄ± bul
        image_files = [f for f in Path(images_dir).iterdir() 
                      if f.suffix.lower() in supported_formats]
        
        if not image_files:
            return {
                'success': False,
                'error': f'GÃ¶rÃ¼ntÃ¼ dosyasÄ± bulunamadÄ±: {images_dir}',
                'processed_count': 0
            }
        
        print(f"ğŸ”„ {len(image_files)} gÃ¶rÃ¼ntÃ¼ iÃ§in toplu konuÅŸan kafa Ã¼retimi...")
        
        # Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        results = []
        success_count = 0
        
        for i, image_file in enumerate(image_files, 1):
            print(f"   [{i}/{len(image_files)}] {image_file.name}")
            
            # Ã‡Ä±ktÄ± dosya yolu
            output_file = output_path / f"talking_{image_file.stem}.mp4"
            
            # KonuÅŸan kafa Ã¼ret
            result = self.generate_talking_head(str(image_file), audio_path, str(output_file))
            results.append(result)
            
            if result['success']:
                success_count += 1
        
        print(f"âœ… Toplu konuÅŸan kafa Ã¼retimi tamamlandÄ±: {success_count}/{len(image_files)} baÅŸarÄ±lÄ±")
        
        return {
            'success': True,
            'images_dir': images_dir,
            'audio_path': audio_path,
            'output_dir': output_dir,
            'total_files': len(image_files),
            'processed_count': success_count,
            'results': results,
            'timestamp': datetime.now().isoformat()
        }

def main():
    parser = argparse.ArgumentParser(description='GeliÅŸmiÅŸ KonuÅŸan Kafa Ãœretim Sistemi')
    parser.add_argument('--image', help='Kaynak gÃ¶rÃ¼ntÃ¼ dosyasÄ±')
    parser.add_argument('--audio', help='Ses dosyasÄ± (wav/mp3)')
    parser.add_argument('--method', choices=['wav2lip', 'sadtalker', 'opencv'], 
                       default='wav2lip', help='Ãœretim yÃ¶ntemi')
    parser.add_argument('--output', help='Ã‡Ä±ktÄ± video yolu')
    parser.add_argument('--batch', action='store_true', 
                       help='Toplu Ã¼retim (image klasÃ¶r olmalÄ±)')
    parser.add_argument('--images-dir', help='GÃ¶rÃ¼ntÃ¼ klasÃ¶rÃ¼ (batch modu iÃ§in)')
    
    args = parser.parse_args()
    
    # KonuÅŸan kafa Ã¼retici oluÅŸtur
    generator = TalkingHeadGenerator(method=args.method)
    
    if args.batch and args.images_dir and args.audio:
        # Toplu Ã¼retim
        result = generator.batch_generate_talking_heads(args.images_dir, args.audio, args.output)
        
        if result['success']:
            print(f"\nğŸ“Š Toplu Ãœretim SonuÃ§larÄ±:")
            print(f"   GÃ¶rÃ¼ntÃ¼ klasÃ¶rÃ¼: {result['images_dir']}")
            print(f"   Ses dosyasÄ±: {result['audio_path']}")
            print(f"   Toplam dosya: {result['total_files']}")
            print(f"   Ä°ÅŸlenen: {result['processed_count']}")
            print(f"   Ã‡Ä±ktÄ± klasÃ¶rÃ¼: {result['output_dir']}")
        else:
            print(f"âŒ Hata: {result['error']}")
    
    elif args.image and args.audio:
        # Tek dosya Ã¼retim
        result = generator.generate_talking_head(args.image, args.audio, args.output)
        
        if result['success']:
            print(f"\nğŸ“Š KonuÅŸan Kafa Ãœretim SonuÃ§larÄ±:")
            print(f"   YÃ¶ntem: {result['method']}")
            print(f"   GÃ¶rÃ¼ntÃ¼: {result['input_image']}")
            print(f"   Ses: {result['input_audio']}")
            print(f"   Ã‡Ä±ktÄ±: {result['output_path']}")
        else:
            print(f"âŒ Hata: {result['error']}")
    
    else:
        print("âŒ LÃ¼tfen gerekli parametreleri belirtin. --help ile yardÄ±m alÄ±n.")
        print("\nÃ–rnek kullanÄ±mlar:")
        print("  python talking_head.py --image face.jpg --audio voice.wav")
        print("  python talking_head.py --images-dir photos/ --audio voice.wav --batch")
        print("  python talking_head.py --image face.jpg --audio voice.wav --method sadtalker")

if __name__ == "__main__":
    main()
